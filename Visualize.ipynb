{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np.loadtxt('data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('data/test.txt').astype(int)\n",
    "ratings = Y_train[:, 2:]\n",
    "mean_rating = np.mean(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution set for CS 155 Set 6, 2016/2017\n",
    "# Authors: Fabian Boemer, Sid Murching, Suraj Nair\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*Ui + eta * Vj * (Yij - np.dot(Ui,Vj))     \n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*Vj + eta * Ui * (Yij - np.dot(Ui,Vj))\n",
    "\n",
    "def get_err(U, V, Y, b1, b2, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    # Compute mean squared error on each data point in Y; include\n",
    "    # regularization penalty in error calculations.\n",
    "    # We first compute the total squared squared error\n",
    "    err = 0.0\n",
    "    for (i,j,Yij) in Y:\n",
    "        err += 0.5 *(Yij - ((np.dot(U[i-1], V[:,j-1])) + mean_rating + b1[i-1] + b2[j-1]))**2\n",
    "    # Add error penalty due to regularization if regularization\n",
    "    # parameter is nonzero\n",
    "    if reg != 0:\n",
    "        U_frobenius_norm = np.linalg.norm(U, ord='fro')\n",
    "        V_frobenius_norm = np.linalg.norm(V, ord='fro')\n",
    "        err += 0.5 * reg * (U_frobenius_norm ** 2)\n",
    "        err += 0.5 * reg * (V_frobenius_norm ** 2)\n",
    "    # Return the mean of the regularized error\n",
    "    return err / float(len(Y))\n",
    "\n",
    "def get_single_err(U, V, i, j, Yij, b1, b2, reg=0.0):\n",
    "    prediction = mean_rating + b1[i-1] + b2[j-1] + (np.dot(U[i-1], V[:,j-1]))\n",
    "    error = Yij - prediction\n",
    "    return error\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    # Initialize U, V  \n",
    "    U = np.random.random((M,K)) - 0.5\n",
    "    V = np.random.random((K,N)) - 0.5\n",
    "    bias_u = np.zeros(M)\n",
    "    bias_v = np.zeros(N)\n",
    "    size = Y.shape[0]\n",
    "    delta = None\n",
    "    indices = np.arange(size)    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Run an epoch of SGD\n",
    "        before_E_in = get_err(U, V, Y, bias_u, bias_v, reg)\n",
    "        np.random.shuffle(indices)\n",
    "        for ind in indices:\n",
    "            (i,j, Yij) = Y[ind]\n",
    "            # Update U[i], V[j]\n",
    "            error = get_single_err(U, V, i, j, Yij, bias_u, bias_v, reg)\n",
    "            bias_u[i-1] += eta * (error - reg * bias_u[i-1])\n",
    "            bias_v[j-1] += eta * (error - reg * bias_v[j-1])\n",
    "            U[i-1] = grad_U(U[i-1], Yij, V[:,j-1], reg, eta)\n",
    "            V[:,j-1] = grad_V(V[:,j-1], Yij, U[i-1], reg, eta);\n",
    "        # At end of epoch, print E_in\n",
    "        E_in = get_err(U, V, Y, bias_u, bias_v, reg)\n",
    "        print(\"Epoch %s, E_in (regularized MSE): %s\"%(epoch + 1, E_in))\n",
    "\n",
    "        # Compute change in E_in for first epoch\n",
    "        if epoch == 0:\n",
    "            delta = before_E_in - E_in\n",
    "\n",
    "        # If E_in doesn't decrease by some fraction <eps>\n",
    "        # of the initial decrease in E_in, stop early \n",
    "        elif before_E_in - E_in < eps * delta:\n",
    "            break\n",
    "    return (U, V, get_err(U, V, Y, bias_u, bias_v, reg), bias_u, bias_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing with  943  users,  1682  movies.\n"
     ]
    }
   ],
   "source": [
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "K = 20 \n",
    "reg = 0.1\n",
    "eps = 0.1\n",
    "eta = 0.03 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.1\n",
      "Epoch 1, E_in (regularized MSE): 0.654179081812\n",
      "Epoch 2, E_in (regularized MSE): 0.494047769858\n",
      "Epoch 3, E_in (regularized MSE): 0.453553424338\n",
      "Epoch 4, E_in (regularized MSE): 0.42560947365\n",
      "Epoch 5, E_in (regularized MSE): 0.40959946625\n",
      "Epoch 6, E_in (regularized MSE): 0.395294534148\n",
      "Epoch 7, E_in (regularized MSE): 0.389071415895\n",
      "Epoch 8, E_in (regularized MSE): 0.379755148686\n",
      "Epoch 9, E_in (regularized MSE): 0.369758697352\n",
      "Epoch 10, E_in (regularized MSE): 0.370075161504\n",
      "Ein:  0.370075161504  Eout:  0.472148622408\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, K, eta, reg))\n",
    "U,V, e_in, bias_u, bias_v = train_model(M, N, K, eta, reg, Y_train, eps)\n",
    "eout = get_err(U, V, Y_test, bias_u, bias_v)\n",
    "print(\"Ein: \", e_in, \" Eout: \", eout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20)\n",
      "(2, 943)\n",
      "(2, 1682)\n"
     ]
    }
   ],
   "source": [
    "A, s, B = np.linalg.svd(V, full_matrices=False)\n",
    "A_2 = A[:, :2]\n",
    "A_2_transpose = np.transpose(A_2)\n",
    "print(A_2_transpose.shape)\n",
    "U_t = np.dot(A_2_transpose, U.transpose())\n",
    "print(U_t.shape)\n",
    "V_t = np.dot(A_2_transpose, V)\n",
    "print(V_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(U_t)):\n",
    "    U_t[i] -= np.mean(U_t[i])\n",
    "    V_t[i] -= np.mean(V_t[i])\n",
    "    U_t[i] /= np.std(U_t[i])\n",
    "    V_t[i] /= np.std(V_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77544502 -1.35707864]\n",
      " [-0.98784665 -0.66430133]\n",
      " [ 1.77880392 -0.37152816]\n",
      " ..., \n",
      " [-1.17367395  0.02589783]\n",
      " [-1.52200354  0.71018566]\n",
      " [-0.36736303  0.42419429]]\n"
     ]
    }
   ],
   "source": [
    "U_vis = np.transpose(U_t)\n",
    "V_vis = np.transpose(V_t)\n",
    "print(U_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
